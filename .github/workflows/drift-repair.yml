name: Infrastructure Drift Repair

on:
  workflow_dispatch:
    inputs:
      drift_report_id:
        description: 'Drift report ID from detection workflow'
        required: true
        type: string
      environment:
        description: 'Environment to repair'
        required: true
        type: choice
        options:
          - prod
          - staging
          - dev
          - africa
          - asia
      repair_scope:
        description: 'Scope of repair'
        required: true
        type: choice
        options:
          - all
          - terraform-only
          - kubernetes-only
          - images-only
      auto_approve:
        description: 'Automatically approve and apply changes'
        required: false
        default: false
        type: boolean
      create_pr:
        description: 'Create PR for manual review instead of direct apply'
        required: false
        default: true
        type: boolean

env:
  TF_VERSION: '1.6.0'
  KUBECTL_VERSION: '1.28.0'
  REPAIR_BRANCH: 'drift-repair/${{ github.event.inputs.drift_report_id }}'

permissions:
  id-token: write
  contents: write
  pull-requests: write
  issues: write

jobs:
  validate-repair-request:
    name: Validate Repair Request
    runs-on: ubuntu-latest
    outputs:
      can_proceed: ${{ steps.validate.outputs.can_proceed }}
      repair_plan: ${{ steps.validate.outputs.repair_plan }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Validate repair prerequisites
        id: validate
        run: |
          echo "Validating repair request for drift report: ${{ github.event.inputs.drift_report_id }}"

          # Check if drift report exists
          if [ ! -d "./drift-history" ]; then
            echo "can_proceed=false" >> $GITHUB_OUTPUT
            echo "::error::Drift history not found"
            exit 1
          fi

          # Validate environment
          if [[ ! "${{ github.event.inputs.environment }}" =~ ^(prod|staging|dev|africa|asia)$ ]]; then
            echo "can_proceed=false" >> $GITHUB_OUTPUT
            echo "::error::Invalid environment specified"
            exit 1
          fi

          # For production, require manual approval
          if [[ "${{ github.event.inputs.environment }}" == "prod" && "${{ github.event.inputs.auto_approve }}" == "true" ]]; then
            echo "can_proceed=false" >> $GITHUB_OUTPUT
            echo "::error::Auto-approval not allowed for production environment"
            exit 1
          fi

          echo "can_proceed=true" >> $GITHUB_OUTPUT

          # Create repair plan
          cat > repair_plan.json <<EOF
          {
            "drift_report_id": "${{ github.event.inputs.drift_report_id }}",
            "environment": "${{ github.event.inputs.environment }}",
            "repair_scope": "${{ github.event.inputs.repair_scope }}",
            "auto_approve": ${{ github.event.inputs.auto_approve }},
            "create_pr": ${{ github.event.inputs.create_pr }},
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          }
          EOF

          echo "repair_plan=$(cat repair_plan.json | jq -c .)" >> $GITHUB_OUTPUT

      - name: Create repair issue
        uses: actions/github-script@v7
        with:
          script: |
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Drift Repair: ${{ github.event.inputs.environment }} - ${{ github.event.inputs.drift_report_id }}`,
              body: `## Drift Repair Request

              **Environment:** ${{ github.event.inputs.environment }}
              **Drift Report:** ${{ github.event.inputs.drift_report_id }}
              **Repair Scope:** ${{ github.event.inputs.repair_scope }}
              **Auto Approve:** ${{ github.event.inputs.auto_approve }}
              **Create PR:** ${{ github.event.inputs.create_pr }}

              ## Status

              Repair workflow initiated. This issue will track the repair progress.

              ## Checklist

              - [ ] Repair validation completed
              - [ ] Terraform drift repaired
              - [ ] Kubernetes drift repaired
              - [ ] Image drift repaired
              - [ ] Changes verified
              - [ ] PR created (if applicable)

              ---

              Workflow Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}`,
              labels: ['drift-repair', 'infrastructure', '${{ github.event.inputs.environment }}']
            });

            core.exportVariable('REPAIR_ISSUE_NUMBER', issue.data.number);

  terraform-drift-repair:
    name: Repair Terraform Drift - ${{ github.event.inputs.environment }}
    needs: validate-repair-request
    if: |
      needs.validate-repair-request.outputs.can_proceed == 'true' &&
      (github.event.inputs.repair_scope == 'all' || github.event.inputs.repair_scope == 'terraform-only')
    runs-on: ubuntu-latest
    outputs:
      changes_applied: ${{ steps.apply.outputs.changes_applied }}
      resources_updated: ${{ steps.apply.outputs.resources_updated }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}
          terraform_wrapper: false

      - name: Azure Login
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Configure Terraform Backend
        run: |
          cat > backend-config.tfvars <<EOF
          resource_group_name  = "${{ secrets.TF_STATE_RESOURCE_GROUP }}"
          storage_account_name = "${{ secrets.TF_STATE_STORAGE_ACCOUNT }}"
          container_name       = "${{ secrets.TF_STATE_CONTAINER }}"
          key                  = "${{ github.event.inputs.environment }}/terraform.tfstate"
          EOF

      - name: Terraform Init
        working-directory: ./infrastructure/terraform/environments/${{ github.event.inputs.environment }}
        run: |
          terraform init -backend-config=../../../../backend-config.tfvars

      - name: Terraform Plan
        id: plan
        working-directory: ./infrastructure/terraform/environments/${{ github.event.inputs.environment }}
        run: |
          terraform plan -out=tfplan.binary -no-color 2>&1 | tee plan.log

          # Check if there are changes
          if grep -q "No changes" plan.log; then
            echo "changes_detected=false" >> $GITHUB_OUTPUT
          else
            echo "changes_detected=true" >> $GITHUB_OUTPUT
          fi

          # Convert plan to JSON for analysis
          terraform show -json tfplan.binary > tfplan.json

      - name: Analyze Plan
        id: analyze
        if: steps.plan.outputs.changes_detected == 'true'
        working-directory: ./infrastructure/terraform/environments/${{ github.event.inputs.environment }}
        run: |
          cat > analyze_plan.py <<'PYTHON'
          import json
          import sys

          with open('tfplan.json', 'r') as f:
              plan = json.load(f)

          changes = {
              'create': [],
              'update': [],
              'delete': [],
              'replace': []
          }

          risks = []

          for resource in plan.get('resource_changes', []):
              actions = resource.get('change', {}).get('actions', [])
              address = resource.get('address', 'unknown')
              resource_type = resource.get('type', 'unknown')

              if 'create' in actions:
                  changes['create'].append(address)
              elif 'update' in actions:
                  changes['update'].append(address)
              elif 'delete' in actions:
                  changes['delete'].append(address)
                  # Deletions are high risk
                  risks.append(f"HIGH RISK: Deletion of {address}")
              elif 'delete' in actions and 'create' in actions:
                  changes['replace'].append(address)
                  # Replacements can cause downtime
                  risks.append(f"MEDIUM RISK: Replacement of {address}")

              # Check for critical resource changes
              if resource_type in ['azurerm_kubernetes_cluster', 'azurerm_postgresql_server', 'azurerm_redis_cache']:
                  if any(action in actions for action in ['delete', 'replace']):
                      risks.append(f"CRITICAL: Changes to production database/cluster: {address}")

          print("## Change Summary")
          print(f"- Resources to create: {len(changes['create'])}")
          print(f"- Resources to update: {len(changes['update'])}")
          print(f"- Resources to delete: {len(changes['delete'])}")
          print(f"- Resources to replace: {len(changes['replace'])}")
          print()

          if risks:
              print("## Risk Assessment")
              for risk in risks:
                  print(f"- {risk}")
              print()

          print("## Detailed Changes")
          print(json.dumps(changes, indent=2))

          # Exit with code 1 if critical risks detected
          if any("CRITICAL" in r for r in risks):
              sys.exit(1)
          PYTHON

          python3 analyze_plan.py > plan_analysis.txt
          cat plan_analysis.txt

          echo "resources_updated=$(cat plan_analysis.txt | grep -c 'Resources to')" >> $GITHUB_OUTPUT

      - name: Wait for Manual Approval
        if: |
          steps.plan.outputs.changes_detected == 'true' &&
          (github.event.inputs.auto_approve != 'true' || github.event.inputs.environment == 'prod')
        uses: trstringer/manual-approval@v1
        with:
          secret: ${{ github.token }}
          approvers: ${{ secrets.DRIFT_REPAIR_APPROVERS }}
          minimum-approvals: ${{ github.event.inputs.environment == 'prod' && 2 || 1 }}
          issue-title: "Approve Terraform Drift Repair - ${{ github.event.inputs.environment }}"
          issue-body: |
            Please review the Terraform plan and approve the drift repair.

            Environment: ${{ github.event.inputs.environment }}
            Drift Report: ${{ github.event.inputs.drift_report_id }}

            Plan Analysis:
            ```
            $(cat ./infrastructure/terraform/environments/${{ github.event.inputs.environment }}/plan_analysis.txt)
            ```

            Full plan output available in workflow artifacts.

      - name: Terraform Apply
        id: apply
        if: steps.plan.outputs.changes_detected == 'true'
        working-directory: ./infrastructure/terraform/environments/${{ github.event.inputs.environment }}
        run: |
          terraform apply -auto-approve tfplan.binary 2>&1 | tee apply.log

          if [ $? -eq 0 ]; then
            echo "changes_applied=true" >> $GITHUB_OUTPUT
            echo "Apply completed successfully"
          else
            echo "changes_applied=false" >> $GITHUB_OUTPUT
            echo "::error::Terraform apply failed"
            exit 1
          fi

      - name: Upload Terraform Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: terraform-repair-logs-${{ github.event.inputs.environment }}
          path: |
            ./infrastructure/terraform/environments/${{ github.event.inputs.environment }}/plan.log
            ./infrastructure/terraform/environments/${{ github.event.inputs.environment }}/apply.log
            ./infrastructure/terraform/environments/${{ github.event.inputs.environment }}/plan_analysis.txt
          retention-days: 90

  kubernetes-drift-repair:
    name: Repair Kubernetes Drift - ${{ github.event.inputs.environment }}
    needs: validate-repair-request
    if: |
      needs.validate-repair-request.outputs.can_proceed == 'true' &&
      (github.event.inputs.repair_scope == 'all' || github.event.inputs.repair_scope == 'kubernetes-only')
    runs-on: ubuntu-latest
    outputs:
      resources_synced: ${{ steps.sync.outputs.resources_synced }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Get AKS Credentials
        run: |
          az aks get-credentials \
            --resource-group citadelbuy-${{ github.event.inputs.environment }}-rg \
            --name citadelbuy-${{ github.event.inputs.environment }}-aks \
            --overwrite-existing

      - name: Install kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: ${{ env.KUBECTL_VERSION }}

      - name: Sync Kubernetes Resources
        id: sync
        run: |
          mkdir -p k8s-repair-logs

          RESOURCES_SYNCED=0

          sync_manifest() {
            local manifest=$1
            local namespace=$2

            echo "Syncing: $manifest to namespace: $namespace"

            # Apply the manifest
            if kubectl apply -f "$manifest" -n "$namespace" 2>&1 | tee -a k8s-repair-logs/sync.log; then
              echo "✓ Synced: $manifest"
              RESOURCES_SYNCED=$((RESOURCES_SYNCED + 1))
            else
              echo "✗ Failed to sync: $manifest"
            fi
          }

          # Sync manifests for the environment
          for env_dir in ./infrastructure/kubernetes/${{ github.event.inputs.environment }} ./infrastructure/kubernetes/production ./infrastructure/kubernetes/staging; do
            if [ -d "$env_dir" ]; then
              for manifest in "$env_dir"/*.yaml; do
                if [ -f "$manifest" ]; then
                  # Extract namespace from manifest or use default
                  namespace=$(grep -m 1 "namespace:" "$manifest" | awk '{print $2}' || echo "default")
                  sync_manifest "$manifest" "$namespace"
                fi
              done
            fi
          done

          echo "resources_synced=$RESOURCES_SYNCED" >> $GITHUB_OUTPUT

          # Fix replica drift
          echo -e "\n## Fixing Replica Drift" | tee -a k8s-repair-logs/sync.log

          kubectl get deployments --all-namespaces -o json | jq -r '
            .items[] |
            select(.spec.replicas != .status.replicas) |
            "\(.metadata.namespace) \(.metadata.name) \(.spec.replicas)"
          ' | while read namespace name replicas; do
            echo "Scaling $namespace/$name to $replicas replicas"
            kubectl scale deployment "$name" -n "$namespace" --replicas="$replicas" 2>&1 | tee -a k8s-repair-logs/sync.log
            RESOURCES_SYNCED=$((RESOURCES_SYNCED + 1))
          done

          # Restart deployments with failed pods
          echo -e "\n## Restarting Failed Deployments" | tee -a k8s-repair-logs/sync.log

          kubectl get pods --all-namespaces --field-selector=status.phase!=Running,status.phase!=Succeeded -o json | \
            jq -r '.items[] | "\(.metadata.namespace) \(.metadata.labels.app // .metadata.generateName)"' | \
            sort -u | while read namespace app; do
              if [ -n "$app" ]; then
                echo "Restarting deployment for app: $namespace/$app"
                kubectl rollout restart deployment -l app="$app" -n "$namespace" 2>&1 | tee -a k8s-repair-logs/sync.log || true
              fi
          done

          echo "Total resources synced: $RESOURCES_SYNCED"

      - name: Verify Cluster Health
        run: |
          echo "## Cluster Health Verification" | tee -a k8s-repair-logs/verification.log

          # Check node status
          echo -e "\n### Node Status" | tee -a k8s-repair-logs/verification.log
          kubectl get nodes -o wide | tee -a k8s-repair-logs/verification.log

          # Check pod status
          echo -e "\n### Pod Status" | tee -a k8s-repair-logs/verification.log
          kubectl get pods --all-namespaces | grep -v "Running\|Completed" | tee -a k8s-repair-logs/verification.log || echo "All pods healthy"

          # Check deployment status
          echo -e "\n### Deployment Status" | tee -a k8s-repair-logs/verification.log
          kubectl get deployments --all-namespaces | tee -a k8s-repair-logs/verification.log

      - name: Upload K8s Repair Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: k8s-repair-logs-${{ github.event.inputs.environment }}
          path: k8s-repair-logs/
          retention-days: 90

  image-drift-repair:
    name: Repair Image Drift - ${{ github.event.inputs.environment }}
    needs: validate-repair-request
    if: |
      needs.validate-repair-request.outputs.can_proceed == 'true' &&
      (github.event.inputs.repair_scope == 'all' || github.event.inputs.repair_scope == 'images-only')
    runs-on: ubuntu-latest
    outputs:
      images_updated: ${{ steps.update.outputs.images_updated }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Get AKS Credentials
        run: |
          az aks get-credentials \
            --resource-group citadelbuy-${{ github.event.inputs.environment }}-rg \
            --name citadelbuy-${{ github.event.inputs.environment }}-aks \
            --overwrite-existing

      - name: Update Deployment Images
        id: update
        run: |
          mkdir -p image-repair-logs

          ACR_NAME="citadelbuy${{ github.event.inputs.environment }}acr"
          IMAGES_UPDATED=0

          echo "# Image Drift Repair" > image-repair-logs/update.log
          echo "" >> image-repair-logs/update.log
          echo "ACR: $ACR_NAME" >> image-repair-logs/update.log
          echo "" >> image-repair-logs/update.log

          # Get latest image tags from ACR
          declare -A latest_tags

          for repo in api web worker recommendation-service ai-gateway; do
            latest_tag=$(az acr repository show-tags \
              --name $ACR_NAME \
              --repository $repo \
              --orderby time_desc \
              --top 1 \
              --output tsv 2>/dev/null || echo "")

            if [ -n "$latest_tag" ]; then
              latest_tags[$repo]=$latest_tag
              echo "Latest tag for $repo: $latest_tag" | tee -a image-repair-logs/update.log
            fi
          done

          # Update deployments with latest images
          for deployment in api web worker recommendation-service ai-gateway; do
            if [ -n "${latest_tags[$deployment]}" ]; then
              namespaces=$(kubectl get deployments --all-namespaces -o json | \
                jq -r ".items[] | select(.metadata.name | contains(\"$deployment\")) | .metadata.namespace" | sort -u)

              for namespace in $namespaces; do
                echo "Updating $namespace/$deployment to ${latest_tags[$deployment]}" | tee -a image-repair-logs/update.log

                kubectl set image deployment/$deployment \
                  $deployment=$ACR_NAME.azurecr.io/$deployment:${latest_tags[$deployment]} \
                  -n $namespace 2>&1 | tee -a image-repair-logs/update.log

                if [ $? -eq 0 ]; then
                  IMAGES_UPDATED=$((IMAGES_UPDATED + 1))

                  # Wait for rollout
                  kubectl rollout status deployment/$deployment -n $namespace --timeout=5m 2>&1 | tee -a image-repair-logs/update.log || true
                fi
              done
            fi
          done

          echo "images_updated=$IMAGES_UPDATED" >> $GITHUB_OUTPUT
          echo "Total images updated: $IMAGES_UPDATED" | tee -a image-repair-logs/update.log

      - name: Verify Image Updates
        run: |
          echo -e "\n## Image Update Verification" | tee -a image-repair-logs/verification.log

          kubectl get pods --all-namespaces -o json | \
            jq -r '.items[] |
              "\(.metadata.namespace) \(.metadata.name) \(.spec.containers[].image)"' | \
            sort | tee -a image-repair-logs/verification.log

      - name: Upload Image Repair Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: image-repair-logs-${{ github.event.inputs.environment }}
          path: image-repair-logs/
          retention-days: 90

  create-repair-pr:
    name: Create Repair Pull Request
    needs:
      - validate-repair-request
      - terraform-drift-repair
      - kubernetes-drift-repair
      - image-drift-repair
    if: |
      always() &&
      github.event.inputs.create_pr == 'true' &&
      needs.validate-repair-request.outputs.can_proceed == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Create repair branch
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          git checkout -b ${{ env.REPAIR_BRANCH }}

      - name: Download all repair logs
        uses: actions/download-artifact@v4
        with:
          path: ./repair-artifacts

      - name: Commit repair documentation
        run: |
          mkdir -p docs/drift-repairs

          cat > docs/drift-repairs/${{ github.event.inputs.drift_report_id }}.md <<'EOF'
          # Drift Repair Report

          **Report ID:** ${{ github.event.inputs.drift_report_id }}
          **Environment:** ${{ github.event.inputs.environment }}
          **Repair Scope:** ${{ github.event.inputs.repair_scope }}
          **Timestamp:** $(date -u +%Y-%m-%dT%H:%M:%SZ)

          ## Summary

          This document records the drift repair actions taken for environment ${{ github.event.inputs.environment }}.

          ## Terraform Changes

          ${{ needs.terraform-drift-repair.outputs.changes_applied == 'true' && 'Applied' || 'No changes' }}

          Resources updated: ${{ needs.terraform-drift-repair.outputs.resources_updated || 0 }}

          ## Kubernetes Resources

          Resources synced: ${{ needs.kubernetes-drift-repair.outputs.resources_synced || 0 }}

          ## Container Images

          Images updated: ${{ needs.image-drift-repair.outputs.images_updated || 0 }}

          ## Artifacts

          All repair logs and artifacts are available in the GitHub Actions run:
          ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

          ## Next Steps

          - [ ] Review repair results
          - [ ] Verify infrastructure health
          - [ ] Update monitoring dashboards
          - [ ] Document root cause
          - [ ] Implement preventive measures
          EOF

          git add docs/drift-repairs/
          git commit -m "docs: add drift repair documentation for ${{ github.event.inputs.drift_report_id }}" || echo "No changes"

          git push origin ${{ env.REPAIR_BRANCH }}

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          branch: ${{ env.REPAIR_BRANCH }}
          title: "Infrastructure Drift Repair - ${{ github.event.inputs.environment }}"
          body: |
            ## Drift Repair Summary

            This PR documents the infrastructure drift repair for environment **${{ github.event.inputs.environment }}**.

            ### Details

            - **Drift Report ID:** ${{ github.event.inputs.drift_report_id }}
            - **Repair Scope:** ${{ github.event.inputs.repair_scope }}
            - **Auto Approved:** ${{ github.event.inputs.auto_approve }}

            ### Changes Applied

            #### Terraform
            - Changes Applied: ${{ needs.terraform-drift-repair.outputs.changes_applied || 'N/A' }}
            - Resources Updated: ${{ needs.terraform-drift-repair.outputs.resources_updated || 0 }}

            #### Kubernetes
            - Resources Synced: ${{ needs.kubernetes-drift-repair.outputs.resources_synced || 0 }}

            #### Container Images
            - Images Updated: ${{ needs.image-drift-repair.outputs.images_updated || 0 }}

            ### Verification

            - [ ] Infrastructure health verified
            - [ ] Application functionality tested
            - [ ] Monitoring alerts reviewed
            - [ ] Documentation updated

            ### Artifacts

            All repair logs are available in the [workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}).

            ---

            **Automated drift repair by GitHub Actions**
          labels: |
            drift-repair
            infrastructure
            ${{ github.event.inputs.environment }}
          reviewers: ${{ secrets.DRIFT_REPAIR_APPROVERS }}

  post-repair-verification:
    name: Post-Repair Verification
    needs:
      - terraform-drift-repair
      - kubernetes-drift-repair
      - image-drift-repair
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Get AKS Credentials
        run: |
          az aks get-credentials \
            --resource-group citadelbuy-${{ github.event.inputs.environment }}-rg \
            --name citadelbuy-${{ github.event.inputs.environment }}-aks \
            --overwrite-existing

      - name: Run Health Checks
        run: |
          mkdir -p verification-logs

          echo "# Post-Repair Health Check" > verification-logs/health-check.md
          echo "" >> verification-logs/health-check.md
          echo "**Environment:** ${{ github.event.inputs.environment }}" >> verification-logs/health-check.md
          echo "**Timestamp:** $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> verification-logs/health-check.md
          echo "" >> verification-logs/health-check.md

          # Check AKS cluster health
          echo "## AKS Cluster Health" >> verification-logs/health-check.md
          echo '```' >> verification-logs/health-check.md
          az aks show \
            --name citadelbuy-${{ github.event.inputs.environment }}-aks \
            --resource-group citadelbuy-${{ github.event.inputs.environment }}-rg \
            --query '{status: provisioningState, powerState: powerState.code, kubernetesVersion: currentKubernetesVersion}' \
            --output table >> verification-logs/health-check.md
          echo '```' >> verification-logs/health-check.md

          # Check pod health
          echo "" >> verification-logs/health-check.md
          echo "## Pod Health Status" >> verification-logs/health-check.md
          echo '```' >> verification-logs/health-check.md
          kubectl get pods --all-namespaces | grep -v "Running\|Completed" >> verification-logs/health-check.md || echo "All pods healthy" >> verification-logs/health-check.md
          echo '```' >> verification-logs/health-check.md

          # Check service endpoints
          echo "" >> verification-logs/health-check.md
          echo "## Service Endpoints" >> verification-logs/health-check.md
          echo '```' >> verification-logs/health-check.md
          kubectl get services --all-namespaces -o wide >> verification-logs/health-check.md
          echo '```' >> verification-logs/health-check.md

          # Check ingress status
          echo "" >> verification-logs/health-check.md
          echo "## Ingress Status" >> verification-logs/health-check.md
          echo '```' >> verification-logs/health-check.md
          kubectl get ingress --all-namespaces >> verification-logs/health-check.md
          echo '```' >> verification-logs/health-check.md

      - name: Run Application Health Tests
        run: |
          echo "" >> verification-logs/health-check.md
          echo "## Application Health Tests" >> verification-logs/health-check.md
          echo '```' >> verification-logs/health-check.md

          # Test API endpoints
          API_URL=$(kubectl get ingress -n production -o jsonpath='{.items[?(@.metadata.name=="api-ingress")].spec.rules[0].host}' 2>/dev/null || echo "")

          if [ -n "$API_URL" ]; then
            echo "Testing API: https://$API_URL/health"
            curl -s -o /dev/null -w "API Health Check: %{http_code}\n" "https://$API_URL/health" >> verification-logs/health-check.md || echo "API health check failed" >> verification-logs/health-check.md
          fi

          echo '```' >> verification-logs/health-check.md

      - name: Upload Verification Report
        uses: actions/upload-artifact@v4
        with:
          name: post-repair-verification-${{ github.event.inputs.environment }}
          path: verification-logs/
          retention-days: 90

  notify-repair-completion:
    name: Notify Repair Completion
    needs:
      - terraform-drift-repair
      - kubernetes-drift-repair
      - image-drift-repair
      - post-repair-verification
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Determine repair status
        id: status
        run: |
          if [[ "${{ needs.terraform-drift-repair.result }}" == "success" || "${{ needs.terraform-drift-repair.result }}" == "skipped" ]] && \
             [[ "${{ needs.kubernetes-drift-repair.result }}" == "success" || "${{ needs.kubernetes-drift-repair.result }}" == "skipped" ]] && \
             [[ "${{ needs.image-drift-repair.result }}" == "success" || "${{ needs.image-drift-repair.result }}" == "skipped" ]]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "emoji=✅" >> $GITHUB_OUTPUT
            echo "color=good" >> $GITHUB_OUTPUT
          else
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "emoji=❌" >> $GITHUB_OUTPUT
            echo "color=danger" >> $GITHUB_OUTPUT
          fi

      - name: Notify Slack
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "${{ steps.status.outputs.emoji }} Drift Repair Completed",
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "${{ steps.status.outputs.emoji }} Drift Repair - ${{ steps.status.outputs.status }}"
                  }
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*Environment:*\n${{ github.event.inputs.environment }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Report ID:*\n${{ github.event.inputs.drift_report_id }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Scope:*\n${{ github.event.inputs.repair_scope }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Status:*\n${{ steps.status.outputs.status }}"
                    }
                  ]
                },
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Results:*\n• Terraform: ${{ needs.terraform-drift-repair.outputs.changes_applied || 'N/A' }}\n• K8s Resources: ${{ needs.kubernetes-drift-repair.outputs.resources_synced || 0 }} synced\n• Images: ${{ needs.image-drift-repair.outputs.images_updated || 0 }} updated"
                  }
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "View Details"
                      },
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Notify Teams
        uses: jdcargile/ms-teams-notification@v1.4
        with:
          github-token: ${{ github.token }}
          ms-teams-webhook-uri: ${{ secrets.TEAMS_WEBHOOK_URL }}
          notification-summary: "Drift Repair ${{ steps.status.outputs.status }} - ${{ github.event.inputs.environment }}"
          notification-color: ${{ steps.status.outputs.color }}
          timezone: UTC
