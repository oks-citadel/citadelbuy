# AlertManager Deployment for Broxiva Production
# Handles alert routing, grouping, and notification delivery
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: alertmanager-pvc
  namespace: broxiva-monitoring
  labels:
    app: alertmanager
    tier: monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: managed-premium
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: broxiva-monitoring
  labels:
    app: alertmanager
    tier: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: ${SLACK_WEBHOOK_URL}
      smtp_smarthost: 'smtp.sendgrid.net:587'
      smtp_from: 'alerts@broxiva.com'
      smtp_auth_username: 'apikey'
      smtp_auth_password: ${SENDGRID_API_KEY}

    # Templates for notification messages
    templates:
      - '/etc/alertmanager/templates/*.tmpl'

    # Route tree for alert distribution
    route:
      receiver: 'default'
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h

      routes:
        # Critical alerts - immediate notification
        - match:
            severity: critical
          receiver: 'critical-alerts'
          group_wait: 10s
          repeat_interval: 5m
          continue: true

        # Warning alerts - less urgent
        - match:
            severity: warning
          receiver: 'warning-alerts'
          group_wait: 30s
          repeat_interval: 2h
          continue: true

        # Info alerts - informational only
        - match:
            severity: info
          receiver: 'info-alerts'
          group_wait: 5m
          repeat_interval: 24h

        # Database alerts
        - match:
            component: database
          receiver: 'database-team'
          group_wait: 30s
          repeat_interval: 1h

        # API alerts
        - match:
            component: api
          receiver: 'backend-team'
          group_wait: 30s
          repeat_interval: 1h

        # Frontend alerts
        - match:
            tier: frontend
          receiver: 'frontend-team'
          group_wait: 30s
          repeat_interval: 1h

    # Inhibition rules to prevent alert flooding
    inhibit_rules:
      # If service is down, don't alert on high latency
      - source_match:
          severity: 'critical'
          alertname: 'ServiceDown'
        target_match:
          severity: 'warning'
        equal: ['job', 'namespace']

      # If node is down, don't alert on pod issues on that node
      - source_match:
          alertname: 'KubernetesNodeNotReady'
        target_match_re:
          alertname: 'Pod.*|Container.*'
        equal: ['node']

      # If cluster is unhealthy, suppress individual component alerts
      - source_match:
          severity: 'critical'
          component: 'cluster'
        target_match:
          severity: 'warning'
        equal: ['cluster']

    # Receiver definitions
    receivers:
      # Default receiver
      - name: 'default'
        slack_configs:
          - channel: '#broxiva-alerts'
            title: 'Alert: {{ .GroupLabels.alertname }}'
            text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}\n{{ end }}'
            send_resolved: true

      # Critical alerts - PagerDuty + Slack + Email
      - name: 'critical-alerts'
        pagerduty_configs:
          - service_key: ${PAGERDUTY_SERVICE_KEY}
            description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'
            severity: 'critical'
            send_resolved: true
        slack_configs:
          - channel: '#broxiva-critical'
            color: 'danger'
            title: 'CRITICAL: {{ .GroupLabels.alertname }}'
            text: |
              *Summary:* {{ .CommonAnnotations.summary }}
              *Description:* {{ .CommonAnnotations.description }}
              *Severity:* {{ .CommonLabels.severity }}
              *Affected Service:* {{ .CommonLabels.job }}
              *Namespace:* {{ .CommonLabels.namespace }}
            send_resolved: true
            actions:
              - type: button
                text: 'View in Grafana'
                url: 'https://grafana.broxiva.com'
              - type: button
                text: 'View Runbook'
                url: 'https://docs.broxiva.com/runbooks/{{ .GroupLabels.alertname }}'
        email_configs:
          - to: 'oncall@broxiva.com'
            headers:
              Subject: '[CRITICAL] {{ .GroupLabels.alertname }} - {{ .CommonLabels.cluster }}'
            html: |
              <h2>Critical Alert: {{ .GroupLabels.alertname }}</h2>
              <p><strong>Summary:</strong> {{ .CommonAnnotations.summary }}</p>
              <p><strong>Description:</strong> {{ .CommonAnnotations.description }}</p>
              <p><strong>Severity:</strong> {{ .CommonLabels.severity }}</p>
              <p><strong>Time:</strong> {{ .StartsAt }}</p>
              <hr>
              <h3>Alert Details:</h3>
              {{ range .Alerts }}
              <p>
                <strong>Instance:</strong> {{ .Labels.instance }}<br>
                <strong>Job:</strong> {{ .Labels.job }}<br>
                <strong>Namespace:</strong> {{ .Labels.namespace }}<br>
              </p>
              {{ end }}
            send_resolved: true

      # Warning alerts - Slack + Email
      - name: 'warning-alerts'
        slack_configs:
          - channel: '#broxiva-warnings'
            color: 'warning'
            title: 'WARNING: {{ .GroupLabels.alertname }}'
            text: |
              *Summary:* {{ .CommonAnnotations.summary }}
              *Description:* {{ .CommonAnnotations.description }}
              *Service:* {{ .CommonLabels.job }}
            send_resolved: true
        email_configs:
          - to: 'devops@broxiva.com'
            headers:
              Subject: '[WARNING] {{ .GroupLabels.alertname }}'
            send_resolved: true

      # Info alerts - Slack only
      - name: 'info-alerts'
        slack_configs:
          - channel: '#broxiva-info'
            color: 'good'
            title: 'INFO: {{ .GroupLabels.alertname }}'
            text: '{{ .CommonAnnotations.summary }}'
            send_resolved: false

      # Database team alerts
      - name: 'database-team'
        slack_configs:
          - channel: '#broxiva-database'
            title: 'Database Alert: {{ .GroupLabels.alertname }}'
            text: |
              *Summary:* {{ .CommonAnnotations.summary }}
              *Component:* {{ .CommonLabels.component }}
            send_resolved: true
        email_configs:
          - to: 'database-team@broxiva.com'
            headers:
              Subject: '[DB Alert] {{ .GroupLabels.alertname }}'

      # Backend team alerts
      - name: 'backend-team'
        slack_configs:
          - channel: '#broxiva-backend'
            title: 'API Alert: {{ .GroupLabels.alertname }}'
            text: '{{ .CommonAnnotations.summary }}'
            send_resolved: true
        email_configs:
          - to: 'backend-team@broxiva.com'
            headers:
              Subject: '[API Alert] {{ .GroupLabels.alertname }}'

      # Frontend team alerts
      - name: 'frontend-team'
        slack_configs:
          - channel: '#broxiva-frontend'
            title: 'Frontend Alert: {{ .GroupLabels.alertname }}'
            text: '{{ .CommonAnnotations.summary }}'
            send_resolved: true
        email_configs:
          - to: 'frontend-team@broxiva.com'
            headers:
              Subject: '[Frontend Alert] {{ .GroupLabels.alertname }}'

  # Alert templates
  default.tmpl: |
    {{ define "slack.broxiva.title" }}
    [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.alertname }}
    {{ end }}

    {{ define "slack.broxiva.text" }}
    {{ range .Alerts }}
    *Alert:* {{ .Annotations.summary }}
    *Description:* {{ .Annotations.description }}
    *Details:*
      • Severity: `{{ .Labels.severity }}`
      • Instance: `{{ .Labels.instance }}`
      • Job: `{{ .Labels.job }}`
    {{ end }}
    {{ end }}

    {{ define "email.broxiva.subject" }}
    [{{ .Status | toUpper }}] {{ .GroupLabels.alertname }} on {{ .CommonLabels.cluster }}
    {{ end }}

    {{ define "email.broxiva.html" }}
    <!DOCTYPE html>
    <html>
    <head>
      <style>
        body { font-family: Arial, sans-serif; }
        .alert { padding: 15px; margin: 10px 0; border-left: 4px solid; }
        .critical { border-color: #d9534f; background-color: #f2dede; }
        .warning { border-color: #f0ad4e; background-color: #fcf8e3; }
        .info { border-color: #5bc0de; background-color: #d9edf7; }
      </style>
    </head>
    <body>
      <h2>Alert Notification</h2>
      {{ range .Alerts }}
      <div class="alert {{ .Labels.severity }}">
        <h3>{{ .Annotations.summary }}</h3>
        <p>{{ .Annotations.description }}</p>
        <ul>
          <li><strong>Severity:</strong> {{ .Labels.severity }}</li>
          <li><strong>Instance:</strong> {{ .Labels.instance }}</li>
          <li><strong>Job:</strong> {{ .Labels.job }}</li>
          <li><strong>Started At:</strong> {{ .StartsAt }}</li>
        </ul>
      </div>
      {{ end }}
    </body>
    </html>
    {{ end }}
---
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-secrets
  namespace: broxiva-monitoring
  labels:
    app: alertmanager
    tier: monitoring
type: Opaque
stringData:
  slack-webhook-url: "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"
  pagerduty-service-key: "YOUR_PAGERDUTY_SERVICE_KEY"
  sendgrid-api-key: "YOUR_SENDGRID_API_KEY"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: broxiva-monitoring
  labels:
    app: alertmanager
    tier: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
        tier: monitoring
    spec:
      serviceAccountName: alertmanager
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: alertmanager
                topologyKey: kubernetes.io/hostname
      containers:
        - name: alertmanager
          image: prom/alertmanager:v0.26.0
          args:
            - '--config.file=/etc/alertmanager/alertmanager.yml'
            - '--storage.path=/alertmanager'
            - '--cluster.advertise-address=0.0.0.0:9093'
            - '--cluster.listen-address=0.0.0.0:9094'
            - '--web.external-url=https://alertmanager.broxiva.com'
            - '--log.level=info'
          ports:
            - containerPort: 9093
              name: web
            - containerPort: 9094
              name: cluster
          env:
            - name: SLACK_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: slack-webhook-url
            - name: PAGERDUTY_SERVICE_KEY
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: pagerduty-service-key
            - name: SENDGRID_API_KEY
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: sendgrid-api-key
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "200m"
          volumeMounts:
            - name: config
              mountPath: /etc/alertmanager
            - name: storage
              mountPath: /alertmanager
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9093
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9093
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3
      volumes:
        - name: config
          configMap:
            name: alertmanager-config
        - name: storage
          persistentVolumeClaim:
            claimName: alertmanager-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: broxiva-monitoring
  labels:
    app: alertmanager
    tier: monitoring
spec:
  type: ClusterIP
  ports:
    - port: 9093
      targetPort: 9093
      protocol: TCP
      name: web
    - port: 9094
      targetPort: 9094
      protocol: TCP
      name: cluster
  selector:
    app: alertmanager
---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager-headless
  namespace: broxiva-monitoring
  labels:
    app: alertmanager
    tier: monitoring
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 9094
      targetPort: 9094
      protocol: TCP
      name: cluster
  selector:
    app: alertmanager
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: alertmanager
  namespace: broxiva-monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: alertmanager
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - services
      - endpoints
      - pods
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: alertmanager
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: alertmanager
subjects:
  - kind: ServiceAccount
    name: alertmanager
    namespace: broxiva-monitoring
---
# Ingress for AlertManager UI
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: alertmanager
  namespace: broxiva-monitoring
  labels:
    app: alertmanager
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: alertmanager-basic-auth
    nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required'
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - alertmanager.broxiva.com
      secretName: alertmanager-tls
  rules:
    - host: alertmanager.broxiva.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: alertmanager
                port:
                  number: 9093
