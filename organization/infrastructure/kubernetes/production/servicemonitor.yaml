# ServiceMonitors for Prometheus Operator
# These enable automatic metrics collection from Broxiva services

---
# ServiceMonitor for API Backend
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: broxiva-api-monitor
  namespace: broxiva-production
  labels:
    app: broxiva-api
    tier: backend
    environment: production
    prometheus: main
spec:
  selector:
    matchLabels:
      app: broxiva-api
      tier: backend
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
      scheme: http
      scrapeTimeout: 10s
      relabelings:
        - sourceLabels: [__meta_kubernetes_pod_name]
          targetLabel: pod
        - sourceLabels: [__meta_kubernetes_namespace]
          targetLabel: namespace
        - sourceLabels: [__meta_kubernetes_pod_node_name]
          targetLabel: node
    - port: http
      interval: 30s
      path: /api/metrics
      scheme: http
      scrapeTimeout: 10s

---
# ServiceMonitor for Web Frontend
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: broxiva-web-monitor
  namespace: broxiva-production
  labels:
    app: broxiva-web
    tier: frontend
    environment: production
    prometheus: main
spec:
  selector:
    matchLabels:
      app: broxiva-web
      tier: frontend
  endpoints:
    - port: http
      interval: 30s
      path: /api/metrics
      scheme: http
      scrapeTimeout: 10s
      relabelings:
        - sourceLabels: [__meta_kubernetes_pod_name]
          targetLabel: pod
        - sourceLabels: [__meta_kubernetes_namespace]
          targetLabel: namespace

---
# ServiceMonitor for Worker Pods
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: broxiva-workers-monitor
  namespace: broxiva-production
  labels:
    tier: worker
    environment: production
    prometheus: main
spec:
  selector:
    matchLabels:
      tier: worker
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
      scheme: http
      scrapeTimeout: 10s
      relabelings:
        - sourceLabels: [__meta_kubernetes_pod_name]
          targetLabel: pod
        - sourceLabels: [__meta_kubernetes_pod_label_app]
          targetLabel: worker_type

---
# PodMonitor for additional pod-level metrics
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: broxiva-pods-monitor
  namespace: broxiva-production
  labels:
    app: broxiva
    environment: production
spec:
  selector:
    matchLabels:
      environment: production
  podMetricsEndpoints:
    - port: metrics
      interval: 30s
      path: /metrics
    - port: http
      interval: 30s
      path: /metrics

---
# PrometheusRule for Alerting Rules
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: broxiva-alerts
  namespace: broxiva-production
  labels:
    app: broxiva
    environment: production
    prometheus: main
spec:
  groups:
    - name: broxiva-api
      interval: 30s
      rules:
        - alert: HighErrorRate
          expr: |
            rate(http_requests_total{job="broxiva-api",status=~"5.."}[5m])
            / rate(http_requests_total{job="broxiva-api"}[5m]) > 0.05
          for: 5m
          labels:
            severity: critical
            component: api
          annotations:
            summary: "High error rate in API ({{ $value | humanizePercentage }})"
            description: "API error rate is above 5% for the last 5 minutes"

        - alert: HighResponseTime
          expr: |
            histogram_quantile(0.95,
              rate(http_request_duration_seconds_bucket{job="broxiva-api"}[5m])
            ) > 2
          for: 5m
          labels:
            severity: warning
            component: api
          annotations:
            summary: "API response time is high ({{ $value }}s)"
            description: "95th percentile response time is above 2 seconds"

        - alert: PodCrashLooping
          expr: |
            rate(kube_pod_container_status_restarts_total{
              namespace="broxiva-production"
            }[15m]) > 0
          for: 15m
          labels:
            severity: critical
          annotations:
            summary: "Pod {{ $labels.pod }} is crash looping"
            description: "Pod has restarted {{ $value }} times in the last 15 minutes"

        - alert: HighMemoryUsage
          expr: |
            container_memory_usage_bytes{
              namespace="broxiva-production",
              pod=~"broxiva-.*"
            } / container_spec_memory_limit_bytes > 0.9
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High memory usage in {{ $labels.pod }}"
            description: "Memory usage is above 90% ({{ $value | humanizePercentage }})"

        - alert: HighCPUUsage
          expr: |
            rate(container_cpu_usage_seconds_total{
              namespace="broxiva-production",
              pod=~"broxiva-.*"
            }[5m]) / container_spec_cpu_quota * 100 > 80
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High CPU usage in {{ $labels.pod }}"
            description: "CPU usage is above 80% ({{ $value }}%)"

        - alert: DatabaseConnectionPoolExhausted
          expr: |
            pg_stat_activity_count{namespace="broxiva-production"}
            / pg_settings_max_connections > 0.8
          for: 5m
          labels:
            severity: warning
            component: database
          annotations:
            summary: "Database connection pool nearly exhausted"
            description: "Using {{ $value | humanizePercentage }} of available connections"

    - name: broxiva-availability
      interval: 30s
      rules:
        - alert: ServiceDown
          expr: |
            up{namespace="broxiva-production"} == 0
          for: 2m
          labels:
            severity: critical
          annotations:
            summary: "Service {{ $labels.job }} is down"
            description: "Service has been down for 2 minutes"

        - alert: HighPodRestartRate
          expr: |
            increase(kube_pod_container_status_restarts_total{
              namespace="broxiva-production"
            }[1h]) > 3
          labels:
            severity: warning
          annotations:
            summary: "Pod {{ $labels.pod }} has high restart rate"
            description: "Pod has restarted {{ $value }} times in the last hour"

        - alert: InsufficientReplicas
          expr: |
            kube_deployment_status_replicas_available{
              namespace="broxiva-production"
            } < kube_deployment_spec_replicas * 0.5
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Deployment {{ $labels.deployment }} has insufficient replicas"
            description: "Less than 50% of desired replicas are available"

---
# Grafana Dashboard ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: broxiva-dashboard
  namespace: broxiva-production
  labels:
    grafana_dashboard: "1"
data:
  broxiva-overview.json: |
    {
      "dashboard": {
        "title": "Broxiva Production Overview",
        "tags": ["broxiva", "production"],
        "timezone": "browser",
        "panels": [
          {
            "title": "Request Rate",
            "targets": [
              {
                "expr": "rate(http_requests_total{namespace=\"broxiva-production\"}[5m])"
              }
            ]
          },
          {
            "title": "Error Rate",
            "targets": [
              {
                "expr": "rate(http_requests_total{namespace=\"broxiva-production\",status=~\"5..\"}[5m])"
              }
            ]
          },
          {
            "title": "Response Time (p95)",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{namespace=\"broxiva-production\"}[5m]))"
              }
            ]
          }
        ]
      }
    }

---
# OBSERVABILITY NOTES:
#
# 1. Metrics Collection:
#    - Prometheus scrapes metrics every 30 seconds
#    - Metrics retention: 15 days in Prometheus, long-term in Thanos/Cortex
#    - Custom application metrics should be exposed at /metrics endpoint
#
# 2. Alert Configuration:
#    - Critical alerts page on-call engineer immediately
#    - Warning alerts notify team channel
#    - Alert fatigue prevention: tune thresholds based on SLOs
#    - Runbooks should be linked in alert annotations
#
# 3. Dashboards:
#    - Create separate dashboards for different services
#    - Include SLI/SLO tracking
#    - Add business metrics alongside technical metrics
#    - Use templating for multi-environment dashboards
#
# 4. Key Metrics to Track:
#    - Request rate, error rate, duration (RED method)
#    - CPU, memory, network, disk (USE method)
#    - Database query performance
#    - Cache hit rates
#    - Queue depths and processing rates
#    - Business KPIs (orders, revenue, user signups)
#
# 5. Integration:
#    - Send critical alerts to PagerDuty/OpsGenie
#    - Post warnings to Slack/Teams
#    - Integrate with incident management system
#    - Link to logs (Loki/CloudWatch) and traces (Jaeger/Tempo)
