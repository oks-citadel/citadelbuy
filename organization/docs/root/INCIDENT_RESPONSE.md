# CitadelBuy Incident Response Guide

**Version:** 1.0.0
**Last Updated:** 2025-12-03
**Owner:** Platform Engineering & SRE Team

## Table of Contents

1. [Incident Severity Classification](#incident-severity-classification)
2. [Escalation Procedures](#escalation-procedures)
3. [Incident Response Workflow](#incident-response-workflow)
4. [Communication Templates](#communication-templates)
5. [Common Issues and Resolutions](#common-issues-and-resolutions)
6. [Post-Incident Review Process](#post-incident-review-process)
7. [On-Call Responsibilities](#on-call-responsibilities)
8. [Tools and Resources](#tools-and-resources)

---

## Incident Severity Classification

### P1: Critical - Production Down

**Impact:** Complete service outage or critical functionality unavailable

**Examples:**
- Entire website/API is unreachable
- Payment processing completely broken
- Database corruption or data loss
- Security breach or active attack
- Complete checkout flow failure

**Response Time:** Immediate (< 5 minutes)
**Update Frequency:** Every 15 minutes
**Resolution Target:** 1 hour

**Immediate Actions:**
1. Page on-call engineer immediately
2. Escalate to Platform Lead and CTO
3. Create war room (Slack channel + video call)
4. Post public status update within 15 minutes
5. All hands on deck - cancel meetings

---

### P2: High - Significant Impact

**Impact:** Major functionality degraded, affecting many users

**Examples:**
- Partial service outage (e.g., search not working)
- Significant performance degradation (>5s response times)
- Payment processing errors affecting >10% of transactions
- Authentication issues affecting user login
- Email/SMS notifications not sending

**Response Time:** 15 minutes
**Update Frequency:** Every 30 minutes
**Resolution Target:** 4 hours

**Immediate Actions:**
1. Notify on-call engineer
2. Escalate to Platform Lead
3. Post status update within 30 minutes
4. Create incident channel in Slack

---

### P3: Medium - Limited Impact

**Impact:** Non-critical functionality affected, workaround available

**Examples:**
- Minor feature not working (e.g., product reviews)
- Performance degradation affecting < 5% of users
- Non-critical third-party integration down
- Monitoring/alerting issues
- Background jobs delayed

**Response Time:** 1 hour
**Update Frequency:** Every 2 hours
**Resolution Target:** 24 hours

**Immediate Actions:**
1. Notify on-call engineer
2. Create incident ticket
3. Implement workaround if possible
4. Schedule fix during business hours

---

### P4: Low - Minimal Impact

**Impact:** Cosmetic issues, minor bugs with minimal user impact

**Examples:**
- UI/UX issues (typos, styling problems)
- Non-critical logging errors
- Documentation issues
- Minor performance optimization opportunities

**Response Time:** Next business day
**Update Frequency:** As needed
**Resolution Target:** 1 week

**Immediate Actions:**
1. Create bug ticket
2. Add to sprint backlog
3. No immediate escalation needed

---

## Escalation Procedures

### Escalation Chain

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. On-Call Engineer (Primary Responder)    â”‚
â”‚    - Initial triage and response            â”‚
â”‚    - Incident assessment                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ (P1/P2 or unresolved after 30 min)
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Platform Lead / Senior Engineer          â”‚
â”‚    - Technical decision making              â”‚
â”‚    - Resource allocation                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ (P1 or unresolved after 1 hour)
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Engineering Manager / CTO                â”‚
â”‚    - Executive decisions                    â”‚
â”‚    - External communication approval        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ (Business impact or legal concerns)
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. CEO / Executive Team                     â”‚
â”‚    - Major business decisions               â”‚
â”‚    - Public relations                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### When to Escalate

**Immediate Escalation (P1):**
- Service completely down
- Data breach suspected
- Payment processing failure
- Cannot identify root cause within 15 minutes

**Timed Escalation:**
- P2 incident unresolved after 1 hour
- P3 incident unresolved after 4 hours
- Need additional resources or expertise
- Issue complexity beyond on-call capability

### Contact Information

```yaml
On-Call Engineer:
  Primary: Check PagerDuty rotation
  Phone: Via PagerDuty
  Slack: @oncall-engineer

Platform Lead:
  Name: [Platform Lead Name]
  Email: platform-lead@citadelbuy.com
  Phone: +1-XXX-XXX-XXXX
  Slack: @platform-lead

Engineering Manager:
  Name: [Engineering Manager Name]
  Email: engineering-manager@citadelbuy.com
  Phone: +1-XXX-XXX-XXXX
  Slack: @eng-manager

CTO:
  Name: [CTO Name]
  Email: cto@citadelbuy.com
  Phone: +1-XXX-XXX-XXXX
  Slack: @cto

Security Team:
  Email: security@citadelbuy.com
  Slack: #security-incidents

DevOps Team:
  Email: devops@citadelbuy.com
  Slack: #devops-incidents
```

---

## Incident Response Workflow

### Phase 1: Detection & Triage (0-5 minutes)

1. **Acknowledge the Alert**
   ```bash
   # Acknowledge in PagerDuty
   # Post in #incidents Slack channel
   "ðŸš¨ INCIDENT DETECTED: [Brief description]
   Severity: P[1-4]
   Acknowledged by: @[your-name]
   Status: Investigating"
   ```

2. **Initial Assessment**
   - What is broken?
   - How many users are affected?
   - What is the business impact?
   - When did it start?

3. **Severity Classification**
   - Assign severity level (P1-P4)
   - Escalate if P1 or P2

### Phase 2: Investigation (5-30 minutes)

1. **Gather Information**
   ```bash
   # Check application health
   curl https://api.citadelbuy.com/api/health/detailed

   # Check pod status
   kubectl get pods -n citadelbuy

   # Check recent deployments
   kubectl rollout history deployment/citadelbuy-api -n citadelbuy

   # Check logs
   kubectl logs -n citadelbuy -l app=citadelbuy-api --tail=200 --timestamps

   # Check Grafana dashboards
   # Open: https://grafana.citadelbuy.com/d/main-dashboard

   # Check error tracking
   # Open: https://sentry.io/citadelbuy
   ```

2. **Hypothesis Formation**
   - What changed recently? (deployments, config, traffic)
   - Are there similar past incidents?
   - Check #incidents channel for patterns

3. **Communication Update**
   ```
   "ðŸ“Š UPDATE [Timestamp]:
   Impact: [Detailed impact description]
   Root Cause: [Suspected or confirmed]
   ETA for resolution: [Best estimate]
   Next update: [Time]"
   ```

### Phase 3: Mitigation (Variable)

1. **Quick Fixes First**
   - Can we rollback? (See DEPLOYMENT_RUNBOOK.md)
   - Can we scale resources?
   - Can we disable problematic feature?
   - Can we fail over to backup?

2. **Implement Fix**
   ```bash
   # Example: Quick rollback
   kubectl rollout undo deployment/citadelbuy-api -n citadelbuy

   # Example: Scale up resources
   kubectl scale deployment/citadelbuy-api -n citadelbuy --replicas=10

   # Example: Disable feature via feature flag
   kubectl set env deployment/citadelbuy-api FEATURE_X_ENABLED=false -n citadelbuy
   ```

3. **Verify Fix**
   - Run smoke tests
   - Monitor metrics for 15 minutes
   - Confirm with affected users if possible

### Phase 4: Recovery & Monitoring (30-60 minutes)

1. **Verify Full Recovery**
   - All health checks passing
   - Error rates back to normal
   - Performance metrics normal
   - No user complaints

2. **Communication Update**
   ```
   "âœ… RESOLVED [Timestamp]:
   Incident has been resolved.
   Root Cause: [Brief description]
   Resolution: [What we did]
   Impact Duration: [Start time - End time]
   Post-incident review: [Link to be added]"
   ```

3. **Continue Monitoring**
   - Watch for 1-2 hours after resolution
   - Set up additional alerts if needed

### Phase 5: Post-Incident Review (24-48 hours)

See [Post-Incident Review Process](#post-incident-review-process)

---

## Communication Templates

### Internal Incident Alert

```markdown
ðŸš¨ INCIDENT: [Brief Title]

**Severity:** P[1-4]
**Status:** [Investigating|Identified|Monitoring|Resolved]
**Started:** [Timestamp]
**Impact:** [Description of user impact]

**Current Situation:**
[What's happening right now]

**Actions Being Taken:**
- [Action 1]
- [Action 2]

**Response Team:**
- Incident Commander: @[name]
- Technical Lead: @[name]
- Communications: @[name]

**Next Update:** [Timestamp]
```

### Customer Status Update (P1/P2)

```markdown
Subject: [URGENT] Service Issue - CitadelBuy Platform

Dear CitadelBuy Users,

We are currently experiencing [brief description of issue]. Our team is actively working to resolve this issue.

**Status:** In Progress
**Impact:** [What functionality is affected]
**Started:** [Timestamp]
**Estimated Resolution:** [Best estimate or "Investigating"]

We will provide updates every [frequency]. You can check our status page at status.citadelbuy.com for real-time updates.

We apologize for any inconvenience this may cause.

Best regards,
CitadelBuy Engineering Team
```

### Customer Resolution Notice

```markdown
Subject: Resolved - CitadelBuy Service Issue

Dear CitadelBuy Users,

The service issue we experienced earlier has been resolved. All systems are now operating normally.

**Issue:** [Brief description]
**Duration:** [Start time - End time]
**Impact:** [What was affected]
**Resolution:** [How we fixed it]

If you continue to experience any issues, please contact our support team at support@citadelbuy.com.

We apologize for the inconvenience and thank you for your patience.

Best regards,
CitadelBuy Engineering Team
```

### Internal Post-Mortem Invitation

```markdown
Subject: Post-Incident Review - [Incident Title]

Team,

We will be conducting a post-incident review for the [incident date] incident.

**Meeting Details:**
- Date: [Date]
- Time: [Time]
- Location: [Meeting room / Video link]
- Duration: 60 minutes

**Attendees:**
- @[incident-responders]
- @[stakeholders]
- Optional: @[team-members]

**Pre-read:**
- Incident timeline: [Link]
- Relevant logs/metrics: [Link]

**Agenda:**
1. Timeline review (10 min)
2. Root cause analysis (20 min)
3. Action items identification (20 min)
4. Process improvements (10 min)

Looking forward to a constructive discussion focused on learning and improvement.

[Your Name]
```

---

## Common Issues and Resolutions

### Issue: High Response Times / Slow Performance

**Symptoms:**
- API response times > 2 seconds
- Frontend loading slowly
- Users reporting timeouts

**Diagnosis:**
```bash
# Check pod resource usage
kubectl top pods -n citadelbuy

# Check database connections
kubectl exec -it deployment/citadelbuy-api -n citadelbuy -- npx prisma studio

# Check slow queries
kubectl run psql-client --rm -it --restart=Never \
  --image=postgres:16-alpine \
  --env="PGPASSWORD=${DB_PASSWORD}" \
  -- psql -h postgres -U citadelbuy -d citadelbuy_production \
  -c "SELECT query, calls, mean_exec_time FROM pg_stat_statements ORDER BY mean_exec_time DESC LIMIT 10;"

# Check Redis latency
kubectl run redis-test --rm -it --restart=Never \
  --image=redis:7-alpine \
  -- redis-cli -h redis --latency
```

**Quick Fixes:**
```bash
# Scale up API pods
kubectl scale deployment/citadelbuy-api -n citadelbuy --replicas=10

# Restart Redis (if cache issues)
kubectl rollout restart deployment/redis -n citadelbuy

# Clear cache
kubectl exec -it deployment/redis -n citadelbuy -- redis-cli FLUSHDB
```

---

### Issue: Database Connection Pool Exhausted

**Symptoms:**
- "too many connections" errors
- "connection timeout" errors
- API returning 500 errors

**Diagnosis:**
```bash
# Check active connections
kubectl run psql-client --rm -it --restart=Never \
  --image=postgres:16-alpine \
  --env="PGPASSWORD=${DB_PASSWORD}" \
  -- psql -h postgres -U citadelbuy -d citadelbuy_production \
  -c "SELECT count(*) FROM pg_stat_activity;"

# Check connection limits
kubectl run psql-client --rm -it --restart=Never \
  --image=postgres:16-alpine \
  --env="PGPASSWORD=${DB_PASSWORD}" \
  -- psql -h postgres -U citadelbuy -d citadelbuy_production \
  -c "SHOW max_connections;"
```

**Quick Fixes:**
```bash
# Kill idle connections
kubectl run psql-client --rm -it --restart=Never \
  --image=postgres:16-alpine \
  --env="PGPASSWORD=${DB_PASSWORD}" \
  -- psql -h postgres -U citadelbuy -d citadelbuy_production \
  -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'idle' AND state_change < NOW() - INTERVAL '5 minutes';"

# Increase connection pool size (temporary)
kubectl set env deployment/citadelbuy-api DATABASE_POOL_SIZE=50 -n citadelbuy
```

---

### Issue: Payment Processing Failures

**Symptoms:**
- Users unable to complete checkout
- Stripe webhook errors
- Payment confirmation failures

**Diagnosis:**
```bash
# Check Stripe webhook logs
kubectl logs -n citadelbuy -l app=citadelbuy-api | grep -i stripe

# Check Stripe dashboard
# https://dashboard.stripe.com/webhooks

# Test Stripe connectivity
curl -X POST https://api.citadelbuy.com/api/checkout/test-stripe \
  -H "Authorization: Bearer ${ADMIN_TOKEN}"
```

**Quick Fixes:**
```bash
# Verify Stripe keys are correct
kubectl get secret citadelbuy-secrets -n citadelbuy -o jsonpath='{.data.STRIPE_SECRET_KEY}' | base64 -d

# Re-register webhooks
kubectl exec -it deployment/citadelbuy-api -n citadelbuy -- \
  npm run stripe:setup-webhooks

# Fallback: Disable checkout temporarily
kubectl set env deployment/citadelbuy-api CHECKOUT_ENABLED=false -n citadelbuy
```

---

### Issue: Email/SMS Notifications Not Sending

**Symptoms:**
- Order confirmations not sent
- Password reset emails not received
- Background job queue backing up

**Diagnosis:**
```bash
# Check email queue
kubectl exec -it deployment/citadelbuy-api -n citadelbuy -- \
  npm run queue:status

# Check SendGrid status
curl https://status.sendgrid.com/api/v2/status.json

# Check logs for email errors
kubectl logs -n citadelbuy -l app=citadelbuy-api | grep -i "email\|sendgrid"
```

**Quick Fixes:**
```bash
# Restart queue workers
kubectl rollout restart deployment/citadelbuy-worker -n citadelbuy

# Clear stuck jobs
kubectl exec -it deployment/citadelbuy-api -n citadelbuy -- \
  npm run queue:clear-failed

# Verify SendGrid API key
kubectl get secret citadelbuy-secrets -n citadelbuy -o jsonpath='{.data.SENDGRID_API_KEY}' | base64 -d
```

---

### Issue: Out of Memory (OOM) Errors

**Symptoms:**
- Pods restarting frequently
- "OOMKilled" status
- Memory usage at 100%

**Diagnosis:**
```bash
# Check pod memory usage
kubectl top pods -n citadelbuy

# Check pod events
kubectl get events -n citadelbuy --sort-by='.lastTimestamp' | grep OOM

# Check memory limits
kubectl get pods -n citadelbuy -o jsonpath='{.items[*].spec.containers[*].resources.limits.memory}'
```

**Quick Fixes:**
```bash
# Increase memory limits
kubectl set resources deployment/citadelbuy-api \
  -n citadelbuy \
  --limits=memory=1Gi \
  --requests=memory=512Mi

# Restart pods to clear memory
kubectl rollout restart deployment/citadelbuy-api -n citadelbuy
```

---

### Issue: Redis Connection Failures

**Symptoms:**
- Cache misses
- Session errors
- "Redis connection refused"

**Diagnosis:**
```bash
# Check Redis pod
kubectl get pods -n citadelbuy -l app=redis

# Test Redis connectivity
kubectl run redis-test --rm -it --restart=Never \
  --image=redis:7-alpine \
  -- redis-cli -h redis PING

# Check Redis memory
kubectl exec -it deployment/redis -n citadelbuy -- redis-cli INFO memory
```

**Quick Fixes:**
```bash
# Restart Redis
kubectl rollout restart deployment/redis -n citadelbuy

# Clear Redis cache
kubectl exec -it deployment/redis -n citadelbuy -- redis-cli FLUSHALL

# Check Redis configuration
kubectl get configmap redis-config -n citadelbuy -o yaml
```

---

### Issue: Elasticsearch Search Not Working

**Symptoms:**
- Search returns no results
- Search errors
- Product indexing failures

**Diagnosis:**
```bash
# Check Elasticsearch health
curl https://elasticsearch.citadelbuy.com/_cluster/health

# Check indices
curl https://elasticsearch.citadelbuy.com/_cat/indices

# Check logs
kubectl logs -n citadelbuy -l app=elasticsearch --tail=100
```

**Quick Fixes:**
```bash
# Reindex products
kubectl exec -it deployment/citadelbuy-api -n citadelbuy -- \
  npm run search:reindex

# Restart Elasticsearch
kubectl rollout restart deployment/elasticsearch -n citadelbuy

# Clear and rebuild index
curl -X DELETE https://elasticsearch.citadelbuy.com/products
kubectl exec -it deployment/citadelbuy-api -n citadelbuy -- \
  npm run search:init
```

---

## Post-Incident Review Process

### Timeline (After Incident Resolution)

- **Within 24 hours:** Schedule post-incident review meeting
- **Within 48 hours:** Conduct review meeting
- **Within 1 week:** Publish post-incident report
- **Within 2 weeks:** Complete action items

### Post-Incident Review Template

```markdown
# Post-Incident Review: [Incident Title]

**Date:** [Incident Date]
**Severity:** P[1-4]
**Duration:** [X hours, Y minutes]
**Incident Commander:** [Name]
**Participants:** [List of responders]

## Executive Summary

[2-3 sentence summary of what happened, impact, and resolution]

## Timeline

| Time (UTC) | Event |
|------------|-------|
| HH:MM | Incident began (first alert) |
| HH:MM | Incident acknowledged by on-call |
| HH:MM | Severity classified as P[X] |
| HH:MM | Root cause identified |
| HH:MM | Fix implemented |
| HH:MM | Service restored |
| HH:MM | Incident closed |

## Impact

**Users Affected:** [Number or percentage]
**Services Affected:** [List of services]
**Business Impact:**
- Revenue lost: $[Amount] (if applicable)
- Orders failed: [Number]
- User complaints: [Number]

## Root Cause Analysis

**What Happened:**
[Detailed technical description]

**Why It Happened:**
[Root cause - not symptoms]

**Contributing Factors:**
- [Factor 1]
- [Factor 2]

## What Went Well

- [Thing 1]
- [Thing 2]

## What Went Wrong

- [Thing 1]
- [Thing 2]

## Action Items

| Action | Owner | Deadline | Status |
|--------|-------|----------|--------|
| Add monitoring for [X] | @engineer | [Date] | Todo |
| Improve documentation on [Y] | @engineer | [Date] | Todo |
| Implement circuit breaker for [Z] | @engineer | [Date] | Todo |

## Lessons Learned

1. [Lesson 1]
2. [Lesson 2]
3. [Lesson 3]

## Appendix

**Relevant Links:**
- Incident Slack thread: [Link]
- Grafana dashboard: [Link]
- Error logs: [Link]
- Code changes: [Link]
```

### Review Meeting Agenda

1. **Timeline Review** (10 minutes)
   - Walk through timeline chronologically
   - No blame, just facts

2. **Root Cause Analysis** (20 minutes)
   - Use "5 Whys" technique
   - Identify contributing factors
   - Document technical details

3. **Action Items** (20 minutes)
   - Preventive measures
   - Detection improvements
   - Response improvements
   - Assign owners and deadlines

4. **Process Improvements** (10 minutes)
   - What worked well
   - What needs improvement
   - Update runbooks/documentation

### Follow-up Actions

1. **Publish Report**
   - Share with engineering team
   - Share summary with company (if P1/P2)
   - Update status page

2. **Track Action Items**
   - Add to sprint backlog
   - Set reminders for deadlines
   - Review in next incident review

3. **Update Documentation**
   - Add to "Common Issues" section
   - Update runbooks
   - Create new alerts/monitors

---

## On-Call Responsibilities

### On-Call Schedule

- **Rotation:** Weekly (Monday 9:00 AM to Monday 9:00 AM)
- **Handoff:** Monday morning standup
- **Coverage:** 24/7 including weekends and holidays
- **Backup:** Secondary on-call for escalation

### On-Call Duties

**During Business Hours (9 AM - 6 PM):**
- Respond to alerts within 5 minutes
- Monitor #alerts Slack channel
- Participate in incident response
- Handle urgent production issues
- Coordinate with team on fixes

**After Hours (6 PM - 9 AM) & Weekends:**
- Respond to P1/P2 alerts within 15 minutes
- Be available by phone and laptop
- Escalate if needed
- Document all actions taken

### Handoff Checklist

**Outgoing On-Call:**
- [ ] Brief incoming on-call on current issues
- [ ] Share any ongoing investigations
- [ ] Review open incidents and tickets
- [ ] Share any known upcoming events (deployments, maintenance)
- [ ] Confirm contact information works
- [ ] Transfer PagerDuty responsibility

**Incoming On-Call:**
- [ ] Test PagerDuty notifications
- [ ] Review Grafana dashboards
- [ ] Check recent alerts and incidents
- [ ] Review deployment schedule
- [ ] Test VPN and kubectl access
- [ ] Ensure laptop is charged and ready

### On-Call Best Practices

1. **Stay Prepared**
   - Keep laptop and phone charged
   - Test access to all systems
   - Review recent changes and deployments
   - Know who to escalate to

2. **Respond Quickly**
   - Acknowledge alerts within 5 minutes
   - Post in #incidents channel
   - Start investigation immediately

3. **Communicate Clearly**
   - Update stakeholders regularly
   - Document all actions
   - Don't disappear without notice

4. **Know Your Limits**
   - Escalate early if uncertain
   - Don't try to fix everything alone
   - Ask for help when needed

5. **Document Everything**
   - Keep timeline of events
   - Record all commands run
   - Note what worked and what didn't

### On-Call Compensation

- **Weekday On-Call:** On-call stipend
- **Weekend/Holiday:** Additional compensation
- **Incident Response:** Time-off-in-lieu for extended incidents

---

## Tools and Resources

### Monitoring & Alerting

- **Grafana:** https://grafana.citadelbuy.com
- **Prometheus:** https://prometheus.citadelbuy.com
- **PagerDuty:** https://citadelbuy.pagerduty.com
- **Status Page:** https://status.citadelbuy.com

### Logging & Debugging

- **Kibana:** https://kibana.citadelbuy.com
- **Sentry:** https://sentry.io/citadelbuy
- **Kubernetes Logs:** `kubectl logs`

### External Services

- **Stripe Dashboard:** https://dashboard.stripe.com
- **SendGrid Dashboard:** https://app.sendgrid.com
- **AWS Console:** https://console.aws.amazon.com

### Documentation

- **Deployment Runbook:** docs/DEPLOYMENT_RUNBOOK.md
- **Troubleshooting Guide:** docs/TROUBLESHOOTING.md
- **Monitoring Setup:** docs/MONITORING_SETUP.md
- **Database Maintenance:** docs/DATABASE_MAINTENANCE.md

### Communication Channels

- **#incidents:** Primary incident channel
- **#alerts:** Automated alerts
- **#devops:** Infrastructure discussions
- **#engineering:** General engineering

### Quick Reference Commands

```bash
# Check overall health
kubectl get pods -n citadelbuy && curl https://api.citadelbuy.com/api/health

# View logs
kubectl logs -n citadelbuy -l app=citadelbuy-api --tail=100 --timestamps

# Restart deployment
kubectl rollout restart deployment/citadelbuy-api -n citadelbuy

# Rollback deployment
kubectl rollout undo deployment/citadelbuy-api -n citadelbuy

# Scale deployment
kubectl scale deployment/citadelbuy-api -n citadelbuy --replicas=10

# Port forward for debugging
kubectl port-forward -n citadelbuy deployment/citadelbuy-api 4000:3000
```

---

## Appendix: Incident Response Checklist

```markdown
## Incident Response Checklist

### Detection (0-5 min)
- [ ] Alert acknowledged in PagerDuty
- [ ] Posted in #incidents Slack channel
- [ ] Severity level assigned (P1-P4)
- [ ] Escalated if P1/P2

### Investigation (5-30 min)
- [ ] Health checks reviewed
- [ ] Logs examined
- [ ] Recent changes identified
- [ ] Metrics/dashboards checked
- [ ] Root cause hypothesis formed
- [ ] Status update posted

### Mitigation (Variable)
- [ ] Quick fix identified
- [ ] Fix implemented and tested
- [ ] Service health verified
- [ ] Status update posted

### Recovery (30-60 min)
- [ ] Full recovery confirmed
- [ ] Monitoring continued
- [ ] Resolution announced
- [ ] Stakeholders notified

### Post-Incident (24-48 hours)
- [ ] Post-incident review scheduled
- [ ] Timeline documented
- [ ] Action items identified
- [ ] Report published
- [ ] Runbooks updated
```

---

**Document Version History:**

- v1.0.0 (2025-12-03): Initial incident response guide
